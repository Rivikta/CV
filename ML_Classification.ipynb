{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First of all, a few notes:\n",
        "* Getting to know ENCODE might be challenging. So please, attend the seminar.\n",
        "* Check the first homework for a quick reminder on general rules.\n",
        "* Leave as many comments as possible: this way, both you and I will know that you understand your code.\n",
        "\n",
        "Remember to submit the feedback! Especially if the homework was too difficult or easy for you."
      ],
      "metadata": {
        "id": "h6rXJxY5aClz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction [1.0]\n",
        "\n",
        "This homework is heavily based on the seminar material. Make sure you have it at hand - it should help a lot.\n",
        "\n",
        "And yes, extra will require you to do the same thing TWICE, minus the machine learning part.\n",
        "\n",
        "![img](http://i0.kym-cdn.com/entries/icons/original/000/017/886/download.jpg)\n",
        "\n",
        "So either copy&paste your code from the main part, or wrap your code in functions beforehand to make it reusable."
      ],
      "metadata": {
        "id": "pHJmy6k1bJm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Know your protocols\n",
        "\n",
        "During the seminar, we covered basic ideas behind ChIP/ATAC-seq protocols. However, you must understand your data clearly before analyzing it.\n",
        "\n",
        "So here are a few questions:\n",
        "* [0.2] List the main experimental(!) steps of the ChIP-seq protocol, its main advantages, and limitations.\n",
        "\n",
        "→\n",
        "\n",
        "* [0.2] Please, do the same for the ATAC-seq protocol.\n",
        "\n",
        "→\n",
        "\n",
        "* [0.1] Are these experiments universal, or should they be repeated for each culture of interest? Why?\n",
        "\n",
        "→\n",
        "\n",
        "* [0.3] Provide a summary of the typical bioinformatic analysis for these assays. Please, list a popular tool for the analysis and its input/output. In what standard format are results stored? (You can/should use information provided in association graph from choosen ENCODE experiment of interest)\n",
        "\n",
        "→"
      ],
      "metadata": {
        "id": "S5r1z_c1bJsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target transcription factors\n",
        "\n",
        "Overall, you need to repeat our seminar work, but this time with more transcriptional factors. I deliberately did not choose any TFs for you, so you can pick your favorite one or just some proteins that look interesting to you.\n",
        "\n",
        "Here is the task:\n",
        "\n",
        "[0.2] Use ENCODE database and pick a tissue or cell culture with a published ATAC-seq experiment and ***3*** ChIP-seq experiments (for your favorite **transcription factors**). **Ensure all experiments are from the same culture and pass routine ENCODE checks.** Provide links to experiments and descriptions of your TFs below.\n",
        "\n",
        "→"
      ],
      "metadata": {
        "id": "aiit4jH9dMmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing [2]"
      ],
      "metadata": {
        "id": "_tGA0Ysjig-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, no code hints this time. Here is what you need to do and how it will be graded:\n",
        "* [1.5] Implement the main workflow: download regions -> calculate intersections / subtractions -> get sequences -> calculate k-mers -> one-hot encode classes -> split into train and test.\n",
        "* [0.5] Create a histogram showing the distribution of region sizes and calculate a table showing overlaps between all experiments. The table should look like this:\n"
      ],
      "metadata": {
        "id": "VbKjUd_fikGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1mbGgAcLagrgIuYhkEST0Uo-duIfAW6oh\" width=\"250\"/>"
      ],
      "metadata": {
        "id": "HMJDPkLMDg-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "(You don't need to make it identical to this picture. Only make sure to plot the legend and labels.)\n",
        "\n",
        "Everything except the primary workflow is extra. You can ignore it and reuse the code from the seminar if you want.\n",
        "\n",
        "**Hints:**\n",
        "* Remember to subsample the data: around 3k examples for each TF and 9k-27k for the background class. Obviously, you should use subsampling only for prototyping and HW, but not when training/tuning a real-world model.\n",
        "* Binding sites for TF can overlap; this is expected. However, here we will use a simplistic worldview and drop such situations. That is, you need to keep and process only specific sites for each TF. If it's not possible - pick a different set of transcription factors.\n",
        "* Comment and describe! To give you a high grade, we need to understand that you interpreted all results correctly."
      ],
      "metadata": {
        "id": "63Am7LaHDW8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code...."
      ],
      "metadata": {
        "id": "q-_v6YtRikyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-check here!\n",
        "\n",
        "Make sure that after this section, you have the following:\n",
        "* `Xtrain`/`Xtest` - table with k-mers, features for our sequences\n",
        "* `Ytrain`/`Ytest` - table with 4 one-hot-encoded columns, one for each class (background + 3 TFs)"
      ],
      "metadata": {
        "id": "5gTYj0cikABW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning [5.5]"
      ],
      "metadata": {
        "id": "dNHW2IQJqIaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "Time to train our fit-predict skills! Your main task is to:\n",
        "* [0.5] Select proper target metric(s). Do you want to use micro- or macro-averaging? Justify your choice.\n",
        "* [1] Train and optimize hyperparameters for the following models: Logistic regression, Decision tree, Random Forest, SVM, and KNN (GB is optional).\n",
        "* [0.5] Justify the parameters grid for each model. What number of cross-validation folds did you use? Why?"
      ],
      "metadata": {
        "id": "0awh0_2pqMS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code...."
      ],
      "metadata": {
        "id": "Q5LigIjQaKea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation\n",
        "\n",
        "* [0.5] Use test set to rank optimized models. Describe and interpret results.\n",
        "* [0.5]  For the model type of your choice, construct and interpret ROC curves (on the same figure) and calculate ROC AUC for:\n",
        "  *  each class according to One-Vs-Rest classifier scheme\n",
        "  *  micro-/macro-averaged OvR\n",
        "* [0.5] Write a custom function that plots ROC curve and calculates ROC AUC.\n",
        "\n",
        "  It should take as an input:\n",
        " * Ground-truth values for the class.\n",
        " * Probabilities predicted by the model.\n",
        "\n",
        "  Don't use sklearn in-built functions that calculate confusion matrix values and TPR/FPR.\n",
        "\n",
        " *Hint: use `numpy.trapz` to calculate AUC.*\n",
        "\n",
        "  Compare with results of sklearn implementationt.\n",
        "  \n",
        "* [1] Interpret features learned by each model (where applicable). Then, compare them to known TF motifs.\n",
        "* [1] Implement your own version of the random forest algorithm, and compare results with the sklearn version. For simplicity, reuse sklearn DecisionTree class. Your model shouldn't support GridSearch, just fit-predict."
      ],
      "metadata": {
        "id": "7QG1vsu9fqQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code...."
      ],
      "metadata": {
        "id": "0jCgY8G8aLqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra points [1.5]\n",
        "\n",
        "Now it's time to do the hard testing! Find another tissue/cell line where we have ATAC-seq and the same set of ChIP-seq experiments available.\n",
        "\n",
        "Then you need to do the following:\n",
        "* [0.15] Download ATAC-seq peaks, extract sequences and predict regions that each TF will bind.\n",
        "* [1] Download ChIP-seq peaks, intersect with the ATAC-seq and compare them to the ML predictions. Next, calculate standard classification metrics (per-class and then macro averaged): $F_1$, precision, recall, accuracy. Drop regions thar overlap between multiple ChIP-seq experiments (like you did for the training).\n",
        "* [0.35] Which model was the best in this scenario? Do we have any other criteria to rank models except for performance? What model would you use for real studies? Why?"
      ],
      "metadata": {
        "id": "P2EuwzDXqRff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code...."
      ],
      "metadata": {
        "id": "Zas-FjZMPdRG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}